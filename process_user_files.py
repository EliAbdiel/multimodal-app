import os
import io
# import getpass
from dotenv import load_dotenv
import chainlit as cl
import PyPDF2
import docx
import base64
from io import BytesIO
from PIL import Image
from langchain.chains import ConversationalRetrievalChain
# from langchain_community.chat_models import ChatOllama
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from langchain_core.output_parsers import StrOutputParser
from create_chain_retriever import create_chain_retriever
from process_text_to_speech import speak_async


load_dotenv(override=True)


# if "GOOGLE_API_KEY" not in os.environ:
#     os.environ["GOOGLE_API_KEY"] = getpass.getpass("xxxxxxxxxx")

llm = ChatGoogleGenerativeAI(
    model=os.environ["GEMINI_MODEL"],
    google_api_key=os.environ["GEMINI_API_KEY"],
    temperature=0.5,
)

# llm = ChatOllama(model="llama3.2:1b")


async def process_pdf(file: cl.File) -> ConversationalRetrievalChain:
    """
    Processes a PDF file to extract text and create a conversational retrieval chain.

    Extracts text from each page of the PDF and passes it to the `create_chain_retriever` 
    function for further processing. Sends a message to the user informing them of the task.

    Parameters:
    ----------
    file : File
        The PDF file to be processed.

    Returns:
    -------
    ConversationalRetrievalChain
        An instance of the conversational retrieval chain created from the 
        extracted text.
    """
    await cl.Message(content=f"Processing the PDF file: **`{file.name}`**... Please hold on!").send()

    pdf = PyPDF2.PdfReader(file.path)
    pdf_text = ""
    for page in pdf.pages:
        pdf_text += page.extract_text()
        
    return await create_chain_retriever(texts=pdf_text, source_prefix="pdf")


async def process_word(file: cl.File) -> ConversationalRetrievalChain:
    """
    Processes a Word document to create a conversational retrieval chain.

    Extracts text from the Word document's paragraphs and passes it to the 
    `create_chain_retriever` function. Sends a message notifying the user.

    Parameters:
    ----------
    file : File
        The Word document to be processed.

    Returns:
    -------
    ConversationalRetrievalChain
        A conversational retrieval chain created from the document's text.
    """
    await cl.Message(content=f"Processing the Word document: **`{file.name}`**... Please wait!").send()
    
    doc = docx.Document(file.path)
    doc_text = "\n".join([para.text for para in doc.paragraphs])
    
    return await create_chain_retriever(texts=doc_text, source_prefix="docx")


def prompt_func(data: dict) -> list:
    """
    Creates a formatted message for the chat model using text and image data.

    Formats the input data into a structure suitable for the 
    chat model, combining both text and image components.

    Parameters:
    ----------
    data : dict
        A dictionary containing the keys "text" and "image", where "text" 
        is the textual content and "image" is a base64 encoded image string.

    Returns:
    -------
    list
        A list containing a HumanMessage formatted with the combined text 
        and image data.
    """
    text = data["text"]
    image = data["image"]

    image_part = {
        "type": "image_url",
        "image_url": f"data:image/jpeg;base64,{image}",
    }

    content_parts = []
    text_part = {"type": "text", "text": text}
    content_parts.append(image_part)
    content_parts.append(text_part)
    
    human_message = [HumanMessage(content=content_parts)]

    return human_message


async def process_img(file: cl.File, user_message: str) -> str:
    """
    Processes an image file and generates a description.

    Converts the image to a base64-encoded string and uses a chat model to describe it.
    Notifies the user about the task and sends the generated description.

    Parameters:
    ----------
    file : File
        The image file to be processed.

    Returns:
    -------
    str
        A description of the image generated by the chat model.
    """
    await cl.Message(content=f"Processing your image file '{file.name}'... Please hold on while I work on it!").send()
    
    pil_image = Image.open(file.path)
    buffered = BytesIO()
    pil_image.save(buffered, format="JPEG")
    img_str_b64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
    
    chain = prompt_func | llm | StrOutputParser()
    answer_chain = await chain.ainvoke({"text": user_message.content, "image": img_str_b64})
    
    await cl.Message(content=answer_chain).send()
        
    return answer_chain


async def handle_attachment(user_message: cl.Message) -> None:
    """
    Handles different types of file attachments from the user message.

    Identifies the file type and processes it accordingly, storing the result in the session.

    Args:
    ----------
    user_message : Message
        The message containing file attachments and user input.
    """
    pdf_files = [file for file in user_message.elements if file.mime == "application/pdf"]
    docx_files = [file for file in user_message.elements if file.mime == "application/vnd.openxmlformats-officedocument.wordprocessingml.document"]
    image_files = [file for file in user_message.elements if file.mime.startswith("image/")]

    if pdf_files:
        file = pdf_files[0]
        chain = await process_pdf(file=file)
        cl.user_session.set("chain", chain)

    elif docx_files:
        file = docx_files[0]
        chain = await process_word(file=file)
        cl.user_session.set("chain", chain)
     
    elif image_files:
        file = image_files[0]
        chain = await process_img(file=file, user_message=user_message)
        cl.user_session.set("chain", chain)


async def handle_files_from_audio_message(elements: list, user_message: str) -> None:
    """
    Processes files attached to an audio message and generates a response.

    Checks the types of files attached to the incoming audio message 
    and processes them accordingly. 

    Parameters:
    ----------
    elements : list
        A list of file elements attached to the audio message.
    user_message : str
        The message sent by the user that will be included in the response.

    Workflow:
    --------
    1. Identify the types of files attached to the audio message.
    2. For each file type:
        - Process the first file found of that type.
        - Store the generated chain if applicable.
    """
    file_types = {
        "pdf": [file for file in elements if file.mime == "application/pdf"],
        "docx": [file for file in elements if file.mime == "application/vnd.openxmlformats-officedocument.wordprocessingml.document"],
        "image": [file for file in elements if file.mime.startswith("image/")],
    }
    
    for file_type, files in file_types.items():
        if files:
            file = files[0]
            try:
                if file_type == "pdf":
                    chain = await process_pdf(file=file) 
                    cl.user_session.set("chain", chain)

                elif file_type == "docx":
                    chain = await process_word(file=file) 
                    cl.user_session.set("chain", chain)

                elif file_type == "image":
                    chain = await process_img(file=file, user_message=user_message) 
                    cl.user_session.set("chain", chain)
                    await speak_async(answer=chain)
                
            except Exception as e:
                print(f"Error during the {file.name} processing: {e}")
                continue